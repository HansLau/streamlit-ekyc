# -*- coding: utf-8 -*-
"""FUnctionized Cleaner Mediapipe-Face-Detector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NhOGoKre4BqOLfAV9UXkR86MFcH4DPpI
"""
import os

import cv2
import matplotlib.pyplot as plt
import mediapipe
import numpy as np
from PIL import Image
import math
import itertools
from deepface import DeepFace
from deepface.commons import distance
from deepface.commons import functions
from deepface import DeepFace
from tensorflow.python.tools import module_util as _module_util

"""# Facial landmarks

HANYANG TRIES FACE ADJUSTMENT

> Find right most for left eye, left most for right eye. then use for correction!
"""

def alignment_procedure(img, left_eye, right_eye):
    #this function aligns given face in img based on left and right eye coordinates
    left_eye_x, left_eye_y = left_eye
    right_eye_x, right_eye_y = right_eye
    #find rotation direction
    if left_eye_y > right_eye_y:
        point_3rd = (right_eye_x, left_eye_y)
        direction = -1 #rotate same direction to clock
    else:
        point_3rd = (left_eye_x, right_eye_y)
        direction = 1 #rotate inverse direction of clock
    #-----------------------
    #find length of triangle edges
    a = distance.findEuclideanDistance(np.array(left_eye), np.array(point_3rd)) #distance.findEuclideanDistance
    b = distance.findEuclideanDistance(np.array(right_eye), np.array(point_3rd)) #distance.findEuclideanDistance
    c = distance.findEuclideanDistance(np.array(right_eye), np.array(left_eye)) 

    #apply cosine rule
    if b != 0 and c != 0: #this multiplication causes division by zero in cos_a calculation
        cos_a = (b*b + c*c - a*a)/(2*b*c)
        angle = np.arccos(cos_a) #angle in radian
        angle = (angle * 180) / math.pi #radian to degree
      
      #rotate base image
        if direction == -1:
            angle = 90 - angle
        img = Image.fromarray(img)
        img = np.array(img.rotate( (direction) * angle)) #img = np.array(img.rotate( -(direction) * angle))
    return img #return img anyway

def align_image(img_base, results, faceModule, display = False):
    #not strict
    if hasattr(img_base, 'dtype') and img_base.dtype != "uint8":
        img_base=img_base/img_base.max()#it's the cadting of float32 to uint8
        img_base=255*img_base#it's the cadting of float32 to uint8
        img_base = img_base.astype(np.uint8)#it's the cadting of float32 to uint8
    img = img_base.copy()

    #EYE LANDMARK DETECT
    LEFT_EYE_INDEXES = list(set(itertools.chain(*faceModule.FACEMESH_LEFT_EYE)))
    RIGHT_EYE_INDEXES = list(set(itertools.chain(*faceModule.FACEMESH_RIGHT_EYE)))
    # imgg = cv2.cvtColor(img_base, cv2.COLOR_BGR2RGB).copy()

    if results.multi_face_landmarks:
        #263, 362 left eye 
        point = results.multi_face_landmarks[0].landmark[362]
        left_eye = (int(img.shape[1] * point.x), int(img.shape[0] * point.y))
        #right eye 133, 33 righteye
        point = results.multi_face_landmarks[0].landmark[133]
        right_eye = (int(img.shape[1] * point.x), int(img.shape[0] * point.y))
    else:
        print("NO Face detected! No eyes found")
        return img_base

    corrected_face = alignment_procedure(img, right_eye, left_eye) #can do after face_crop?? hmm

    if display:
        plt.imshow(corrected_face)
        plt.show()

    return corrected_face

#FACE CROP ALGO

def face_crop(img, results, faceModule, display = False):
    if hasattr(img, 'dtype') and img.dtype != "uint8":
        img=img/img.max()#it's the cadting of float32 to uint8
        img=255*img#it's the cadting of float32 to uint8
        img = img.astype(np.uint8)#it's the cadting of float32 to uint8

    imgg = img.copy()

    blank = np.zeros((img.shape[0], img.shape[1])).astype(np.uint8)
    routes = []
    routes2 = []

    # faceModule = mediapipe.solutions.face_mesh
    # face_mesh = faceModule.FaceMesh(static_image_mode=True)
    # results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    if not results.multi_face_landmarks: #doesnt work??
        print("NO face found to crop")
        return img

    landmarks = results.multi_face_landmarks[0]
    for source_idx, target_idx in faceModule.FACEMESH_FACE_OVAL:
        source = landmarks.landmark[source_idx]
        target = landmarks.landmark[target_idx]

        relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))
        relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))

        routes.append(relative_source)
        routes.append(relative_target)
        routes2.append(relative_source)

        cv2.line(blank, relative_source, relative_target, (255, 255, 255), thickness = 2)
        cv2.circle(imgg, (relative_source[0], relative_source[1]), 1, (0, 0, 255), -1) #5
      
    if display:
        fig = plt.figure(figsize = (15, 15))
        plt.imshow(imgg[:, :, ::-1])
        plt.show()

    thresh = cv2.threshold(blank.astype(np.uint8), 120, 255, cv2.THRESH_BINARY)[1]
    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = cnts[0] if len(cnts) == 2 else cnts[1]

    mask = np.zeros((img.shape[0], img.shape[1]))
    for c in cnts:
        cv2.drawContours(mask, [c], -1, (255,255,255), -1)
    mask = mask.astype(bool)
    # plt.imshow(mask)
    # plt.show()

    cropped = np.zeros_like(img)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    cropped[mask] = img[mask]
    
    if display:
        plt.imshow(cropped)
    return cropped

from deepface.commons.functions import normalize_input, preprocess_face
def faceWrapper(img, display = False): #[:, :, ::-1]

    faceModule = mediapipe.solutions.face_mesh
    face_mesh = faceModule.FaceMesh(static_image_mode=True)
    results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

    # img = normalize_input(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), 'mediapipe')
    # img = face_crop(img, results, faceModule, display)
    img = align_image(img, results,faceModule, display)
    # img = detectFace(img, detector_backend = 'mediapipe', enforce_detection = False, align = False)

    #CROP IMAGE USING FACE BOUNDING BOX, future work

    return img

"""TEST ALIGN NORMALIZED PIC"""
# img_base = cv2.imread("8.jpg")
# #IMG PROVVIDEWD

# img = faceWrapper(img_base)
# plt.imshow(img); plt.show()

###
####
# **DEEPFACE FOR ARCFACE RECOGNITION**
#Get IC image cropped
if __name__ == "__main__":
    dir_path = os.path.dirname(os.path.realpath(__file__))
    metrics = ["cosine", "euclidean", "euclidean_l2"]
    # picList = ["hy (1).jpg","hy (2).jpg","hy (3).jpg","hy (4).jpg","hy (5).jpg","hy (6).jpg","hy (7).jpg","hy (8).jpg","hy (9).jpg","hy (10).jpg","hy (11).jpg","hy (12).jpg"]
    picList = [dir_path+"/real_face/dad (1).jpg",dir_path+"/real_face/dad (2).jpg",dir_path+"/real_face/dad (3).jpg"]
    verification = []
    picsToVerify=[]
    verification2 = []

    ic_pic = dir_path+"/real_face/dad.jpg"
    # camera_pic = "hy2.jpg"
    face = faceWrapper(cv2.imread(ic_pic))

    for i in range(len(picList)):
        print(picList[i])
        # face2 = faceWrapper(cv2.imread(picList[i]))
        face2 = cv2.imread(picList[i])
        picsToVerify.append([face2.copy(), face])

    detector_backend = 'retinaface' # 'mediapipe' WITHOUT ALIGN=TRUE, 'opencv'
    result = DeepFace.verify(img1_path = picsToVerify, model_name = "ArcFace", distance_metric = metrics[1], enforce_detection = False, detector_backend = detector_backend,  normalization = 'ArcFace')
    [verification.append([result[a]['verified'],result[a]['distance'],a]) for a in result]
    print(verification)



"""**Mouth Detector**"""

# from IPython.display import display, Javascript
# from google.colab.output import eval_js
# from base64 import b64decode

# def take_photo(filename='photo.jpg', quality=0.8):
#   js = Javascript('''
#     async function takePhoto(quality) {
#       const div = document.createElement('div');
#       const capture = document.createElement('button');
#       capture.textContent = 'Capture';
#       div.appendChild(capture);

#       const video = document.createElement('video');
#       video.style.display = 'block';
#       const stream = await navigator.mediaDevices.getUserMedia({video: true});

#       document.body.appendChild(div);
#       div.appendChild(video);
#       video.srcObject = stream;
#       await video.play();

#       // Resize the output to fit the video element.
#       google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

#       // Wait for Capture to be clicked.
#       await new Promise((resolve) => capture.onclick = resolve);

#       const canvas = document.createElement('canvas');
#       canvas.width = video.videoWidth;
#       canvas.height = video.videoHeight;
#       canvas.getContext('2d').drawImage(video, 0, 0);
#       stream.getVideoTracks()[0].stop();
#       div.remove();
#       return canvas.toDataURL('image/jpeg', quality);
#     }
#     ''')
#   display(js)
#   data = eval_js('takePhoto({})'.format(quality))
#   binary = b64decode(data.split(',')[1])
#   with open(filename, 'wb') as f:
#     f.write(binary)
#   return filename

"""Take pic of Face if detected module

"""